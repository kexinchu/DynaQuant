#!/usr/bin/env python3
"""
è®¾å¤‡ä¿®å¤æµ‹è¯•è„šæœ¬
"""

import torch
import logging
from fix_device_issues import (
    ensure_model_on_device,
    fix_tokenizer_device_issues,
    create_proper_attention_mask,
    validate_model_device_consistency,
    comprehensive_device_fix
)

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def test_device_fix_functions():
    """æµ‹è¯•è®¾å¤‡ä¿®å¤å‡½æ•°"""
    print("=" * 60)
    print("æµ‹è¯•è®¾å¤‡ä¿®å¤å‡½æ•°")
    print("=" * 60)
    
    # åˆ›å»ºä¸€ä¸ªç®€å•çš„æµ‹è¯•æ¨¡å‹
    class TestModel(torch.nn.Module):
        def __init__(self):
            super().__init__()
            self.linear1 = torch.nn.Linear(10, 20)
            self.linear2 = torch.nn.Linear(20, 5)
        
        def forward(self, x):
            return self.linear2(self.linear1(x))
    
    # åˆ›å»ºæ¨¡å‹
    model = TestModel()
    print(f"åŸå§‹æ¨¡å‹è®¾å¤‡: {next(model.parameters()).device}")
    
    # æµ‹è¯•è®¾å¤‡ä¿®å¤
    if torch.cuda.is_available():
        device = "cuda"
        print(f"ä½¿ç”¨CUDAè®¾å¤‡: {device}")
        
        # æµ‹è¯•ensure_model_on_device
        model_fixed = ensure_model_on_device(model, device)
        print(f"ä¿®å¤åæ¨¡å‹è®¾å¤‡: {next(model_fixed.parameters()).device}")
        
        # æµ‹è¯•éªŒè¯å‡½æ•°
        validation = validate_model_device_consistency(model_fixed, device)
        print(f"è®¾å¤‡ä¸€è‡´æ€§éªŒè¯: {validation['is_consistent']}")
        
        if not validation['is_consistent']:
            print(f"å‘ç°çš„é—®é¢˜: {validation['issues']}")
    else:
        print("CUDAä¸å¯ç”¨ï¼Œè·³è¿‡è®¾å¤‡æµ‹è¯•")
    
    print("âœ“ è®¾å¤‡ä¿®å¤å‡½æ•°æµ‹è¯•å®Œæˆ")


def test_attention_mask_creation():
    """æµ‹è¯•æ³¨æ„åŠ›æ©ç åˆ›å»º"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•æ³¨æ„åŠ›æ©ç åˆ›å»º")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿtokenizer
    class MockTokenizer:
        def __init__(self):
            self.pad_token_id = 0
            self.eos_token_id = 0  # ç›¸åŒçš„æƒ…å†µ
    
    tokenizer = MockTokenizer()
    
    # åˆ›å»ºæµ‹è¯•è¾“å…¥
    input_ids = torch.tensor([[1, 2, 3, 0, 0], [1, 2, 0, 0, 0]])  # åŒ…å«padding
    
    # æµ‹è¯•æ³¨æ„åŠ›æ©ç åˆ›å»º
    attention_mask = create_proper_attention_mask(input_ids, tokenizer, "cpu")
    print(f"è¾“å…¥å½¢çŠ¶: {input_ids.shape}")
    print(f"æ³¨æ„åŠ›æ©ç å½¢çŠ¶: {attention_mask.shape}")
    print(f"æ³¨æ„åŠ›æ©ç :\n{attention_mask}")
    
    print("âœ“ æ³¨æ„åŠ›æ©ç åˆ›å»ºæµ‹è¯•å®Œæˆ")


def test_tokenizer_fix():
    """æµ‹è¯•tokenizerä¿®å¤"""
    print("\n" + "=" * 60)
    print("æµ‹è¯•tokenizerä¿®å¤")
    print("=" * 60)
    
    # æ¨¡æ‹Ÿæœ‰é—®é¢˜çš„tokenizer
    class MockTokenizer:
        def __init__(self):
            self.pad_token_id = None
            self.eos_token_id = 2
            self.unk_token_id = 1
            self.pad_token = None
            self.eos_token = None
    
    tokenizer = MockTokenizer()
    print(f"ä¿®å¤å‰ - pad_token_id: {tokenizer.pad_token_id}")
    print(f"ä¿®å¤å‰ - eos_token: {tokenizer.eos_token}")
    
    # ä¿®å¤tokenizer
    fixed_tokenizer = fix_tokenizer_device_issues(tokenizer, "cpu")
    print(f"ä¿®å¤å - pad_token_id: {fixed_tokenizer.pad_token_id}")
    print(f"ä¿®å¤å - eos_token: {fixed_tokenizer.eos_token}")
    
    print("âœ“ tokenizerä¿®å¤æµ‹è¯•å®Œæˆ")


def main():
    """ä¸»å‡½æ•°"""
    print("è®¾å¤‡ä¿®å¤æµ‹è¯•")
    print("=" * 60)
    
    # è¿è¡Œæ‰€æœ‰æµ‹è¯•
    tests = [
        ("è®¾å¤‡ä¿®å¤å‡½æ•°", test_device_fix_functions),
        ("æ³¨æ„åŠ›æ©ç åˆ›å»º", test_attention_mask_creation),
        ("tokenizerä¿®å¤", test_tokenizer_fix)
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"\nè¿è¡Œæµ‹è¯•: {test_name}")
        try:
            test_func()
            results.append((test_name, True))
        except Exception as e:
            print(f"âœ— æµ‹è¯•å¤±è´¥: {e}")
            results.append((test_name, False))
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 60)
    print("æµ‹è¯•ç»“æœæ±‡æ€»")
    print("=" * 60)
    
    for test_name, result in results:
        status = "âœ“ é€šè¿‡" if result else "âœ— å¤±è´¥"
        print(f"{test_name}: {status}")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    print(f"\næ€»è®¡: {passed}/{total} ä¸ªæµ‹è¯•é€šè¿‡")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰è®¾å¤‡ä¿®å¤æµ‹è¯•é€šè¿‡ï¼")
        print("\nä¿®å¤è¯´æ˜:")
        print("1. æ¨¡å‹è®¾å¤‡ä¸€è‡´æ€§æ£€æŸ¥")
        print("2. æ³¨æ„åŠ›æ©ç æ­£ç¡®åˆ›å»º")
        print("3. tokenizerç‰¹æ®Štokenä¿®å¤")
        print("4. MoEæ¨¡å—è®¾å¤‡é—®é¢˜ä¿®å¤")
    else:
        print("âš  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œéœ€è¦è¿›ä¸€æ­¥è°ƒè¯•ã€‚")


if __name__ == "__main__":
    main()
