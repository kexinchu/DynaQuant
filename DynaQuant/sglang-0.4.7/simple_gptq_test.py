#!/usr/bin/env python3
"""
ç®€å•çš„GPTQæµ‹è¯•è„šæœ¬
"""

import torch

def test_gptq_fix():
    """æµ‹è¯•GPTQä¿®å¤"""
    print("æµ‹è¯•GPTQåé‡åŒ–ä¿®å¤")
    
    # åˆ›å»ºæµ‹è¯•æ•°æ®ï¼ˆåŸºäºé”™è¯¯ä¿¡æ¯ä¸­çš„å½¢çŠ¶ï¼‰
    qweight = torch.randint(0, 16, (256, 768), dtype=torch.int32)
    qzeros = torch.randint(0, 16, (16, 96), dtype=torch.int32)
    scales = torch.randn(16, 768, dtype=torch.float16)
    
    print(f"è¾“å…¥å½¢çŠ¶:")
    print(f"  qweight: {qweight.shape}")
    print(f"  qzeros: {qzeros.shape}")
    print(f"  scales: {scales.shape}")
    
    # è§£åŒ…int32åˆ°int4
    def unpack_int32_to_int4(packed):
        batch_size, seq_len = packed.shape
        unpacked = torch.zeros(batch_size, seq_len * 8, dtype=torch.int32)
        
        for i in range(8):
            shift = i * 4
            mask = 0xF
            unpacked[:, i::8] = (packed >> shift) & mask
        
        return unpacked
    
    unpacked = unpack_int32_to_int4(qweight)
    print(f"è§£åŒ…åå½¢çŠ¶: {unpacked.shape}")
    
    # è®¡ç®—ç»´åº¦
    out_features = qweight.shape[0]  # 256
    in_features = scales.shape[1]    # 768
    group_size = in_features // scales.shape[0]  # 768 // 16 = 48
    
    print(f"è®¡ç®—çš„ç»´åº¦:")
    print(f"  out_features: {out_features}")
    print(f"  in_features: {in_features}")
    print(f"  group_size: {group_size}")
    
    # åé‡åŒ–é›¶ç‚¹
    zeros = qzeros * scales
    print(f"zeroså½¢çŠ¶: {zeros.shape}")
    
    # æ‰©å±•scaleså’Œzeros
    scales_expanded = scales.repeat(group_size, 1)
    zeros_expanded = zeros.repeat(group_size, 1)
    
    print(f"æ‰©å±•åå½¢çŠ¶:")
    print(f"  scales_expanded: {scales_expanded.shape}")
    print(f"  zeros_expanded: {zeros_expanded.shape}")
    
    # ç¡®ä¿ç»´åº¦åŒ¹é…
    if scales_expanded.shape[1] != unpacked.shape[1]:
        if scales_expanded.shape[1] < unpacked.shape[1]:
            factor = unpacked.shape[1] // scales_expanded.shape[1]
            scales_expanded = scales_expanded.repeat(1, factor)
            zeros_expanded = zeros_expanded.repeat(1, factor)
        else:
            unpacked = unpacked[:, :scales_expanded.shape[1]]
    
    print(f"ç»´åº¦åŒ¹é…å:")
    print(f"  scales_expanded: {scales_expanded.shape}")
    print(f"  zeros_expanded: {zeros_expanded.shape}")
    print(f"  unpacked: {unpacked.shape}")
    
    # åº”ç”¨åé‡åŒ–å…¬å¼
    weight = scales_expanded * (unpacked.float() - zeros_expanded)
    
    # è½¬ç½®åˆ°æ­£ç¡®çš„å½¢çŠ¶
    weight = weight.t()
    
    print(f"æœ€ç»ˆæƒé‡å½¢çŠ¶: {weight.shape}")
    
    # éªŒè¯å½¢çŠ¶
    expected_shape = (768, 256)  # [in_features, out_features]
    if weight.shape == expected_shape:
        print("âœ“ å½¢çŠ¶æ­£ç¡®ï¼")
        return True
    else:
        print(f"âš  å½¢çŠ¶ä¸åŒ¹é…: æœŸæœ› {expected_shape}, å®é™… {weight.shape}")
        return False

if __name__ == "__main__":
    success = test_gptq_fix()
    if success:
        print("ğŸ‰ GPTQä¿®å¤æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âŒ GPTQä¿®å¤æµ‹è¯•å¤±è´¥ï¼")
