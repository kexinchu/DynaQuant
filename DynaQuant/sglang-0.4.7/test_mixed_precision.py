#!/usr/bin/env python3
"""
SGLangæ··åˆç²¾åº¦åŠŸèƒ½æµ‹è¯•è„šæœ¬
"""

import os
import sys
import time
import requests
import json
from pathlib import Path

# æ·»åŠ sglangè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "python"))

import sglang as sgl


def test_health_check(server_url: str):
    """æµ‹è¯•å¥åº·æ£€æŸ¥"""
    print("=" * 50)
    print("æµ‹è¯•å¥åº·æ£€æŸ¥")
    print("=" * 50)
    
    try:
        response = requests.get(f"{server_url}/health")
        if response.status_code == 200:
            data = response.json()
            print(f"æœåŠ¡å™¨çŠ¶æ€: {data.get('status', 'unknown')}")
            print(f"æ¨¡å‹å·²åŠ è½½: {data.get('model_loaded', False)}")
            print(f"è®¾å¤‡: {data.get('device', 'unknown')}")
            return True
        else:
            print(f"å¥åº·æ£€æŸ¥å¤±è´¥: HTTP {response.status_code}")
            return False
    except Exception as e:
        print(f"å¥åº·æ£€æŸ¥å¼‚å¸¸: {e}")
        return False


def test_sglang_api(server_url: str):
    """æµ‹è¯•SGLang API"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•SGLang API")
    print("=" * 50)
    
    try:
        # è®¾ç½®åç«¯
        sgl.set_default_backend(server_url)
        
        # åˆ›å»ºæç¤º
        prompt = "è¯·ä»‹ç»ä¸€ä¸‹äººå·¥æ™ºèƒ½çš„å‘å±•å†å²ï¼š"
        
        # ç”Ÿæˆæ–‡æœ¬
        start_time = time.time()
        response = sgl.generate(
            prompt, 
            max_new_tokens=100, 
            temperature=0.7,
            top_p=0.9
        )
        generation_time = time.time() - start_time
        
        print(f"è¾“å…¥æç¤º: {prompt}")
        print(f"ç”Ÿæˆæ–‡æœ¬: {response.text}")
        print(f"ç”Ÿæˆæ—¶é—´: {generation_time:.2f}ç§’")
        
        return True
        
    except Exception as e:
        print(f"SGLang APIæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_batch_generation(server_url: str):
    """æµ‹è¯•æ‰¹é‡ç”Ÿæˆ"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ‰¹é‡ç”Ÿæˆ")
    print("=" * 50)
    
    try:
        # è®¾ç½®åç«¯
        sgl.set_default_backend(server_url)
        
        # æ‰¹é‡æç¤º
        prompts = [
            "ä»€ä¹ˆæ˜¯æœºå™¨å­¦ä¹ ï¼Ÿ",
            "æ·±åº¦å­¦ä¹ ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
            "è¯·è§£é‡Šä¸€ä¸‹ç¥ç»ç½‘ç»œçš„å·¥ä½œåŸç†ã€‚"
        ]
        
        # æ‰¹é‡ç”Ÿæˆ
        start_time = time.time()
        responses = []
        for prompt in prompts:
            response = sgl.generate(
                prompt, 
                max_new_tokens=50, 
                temperature=0.8
            )
            responses.append(response.text)
        batch_time = time.time() - start_time
        
        print(f"æ‰¹é‡ç”Ÿæˆæ—¶é—´: {batch_time:.2f}ç§’")
        print("\nç”Ÿæˆç»“æœ:")
        for i, (prompt, text) in enumerate(zip(prompts, responses)):
            print(f"\n{i+1}. è¾“å…¥: {prompt}")
            print(f"   è¾“å‡º: {text}")
        
        return True
        
    except Exception as e:
        print(f"æ‰¹é‡ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")
        return False


def test_mixed_precision_info(server_url: str):
    """æµ‹è¯•æ··åˆç²¾åº¦ä¿¡æ¯æŸ¥è¯¢"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ··åˆç²¾åº¦ä¿¡æ¯æŸ¥è¯¢")
    print("=" * 50)
    
    try:
        # å°è¯•è·å–æ¨¡å‹ä¿¡æ¯
        response = requests.get(f"{server_url}/model_info")
        if response.status_code == 200:
            data = response.json()
            print("æ¨¡å‹ä¿¡æ¯:")
            print(f"  æ¨¡å‹åç§°: {data.get('model_name', 'unknown')}")
            print(f"  è®¾å¤‡: {data.get('device', 'unknown')}")
            print(f"  æ•°æ®ç±»å‹: {data.get('dtype', 'unknown')}")
            print(f"  æœ€å¤§åºåˆ—é•¿åº¦: {data.get('max_seq_length', 'unknown')}")
            print(f"  æœ€å¤§æ‰¹å¤„ç†å¤§å°: {data.get('max_batch_size', 'unknown')}")
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ··åˆç²¾åº¦ä¿¡æ¯
            weight_info = data.get('weight_info', {})
            if weight_info:
                print("\næƒé‡ä¿¡æ¯:")
                print(f"  ç²¾åº¦è·¯å¾„: {weight_info.get('precision_paths', {})}")
                print(f"  æƒé‡æ˜ å°„æ•°é‡: {len(weight_info.get('weight_mapping', {}))}")
                print(f"  ç¼“å­˜æ–‡ä»¶æ•°é‡: {len(weight_info.get('cached_files', []))}")
            
            return True
        else:
            print(f"æ¨¡å‹ä¿¡æ¯æŸ¥è¯¢å¤±è´¥: HTTP {response.status_code}")
            return False
            
    except Exception as e:
        print(f"æ¨¡å‹ä¿¡æ¯æŸ¥è¯¢å¼‚å¸¸: {e}")
        return False


def test_performance_comparison(server_url: str):
    """æµ‹è¯•æ€§èƒ½å¯¹æ¯”"""
    print("\n" + "=" * 50)
    print("æµ‹è¯•æ€§èƒ½å¯¹æ¯”")
    print("=" * 50)
    
    try:
        # è®¾ç½®åç«¯
        sgl.set_default_backend(server_url)
        
        # æµ‹è¯•æç¤º
        test_prompts = [
            "äººå·¥æ™ºèƒ½æ˜¯ä»€ä¹ˆï¼Ÿ",
            "æœºå™¨å­¦ä¹ çš„åŸºæœ¬åŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
            "æ·±åº¦å­¦ä¹ ä¸ä¼ ç»Ÿæœºå™¨å­¦ä¹ æœ‰ä»€ä¹ˆåŒºåˆ«ï¼Ÿ",
            "ç¥ç»ç½‘ç»œæ˜¯å¦‚ä½•å·¥ä½œçš„ï¼Ÿ",
            "ä»€ä¹ˆæ˜¯å¼ºåŒ–å­¦ä¹ ï¼Ÿ"
        ]
        
        # æµ‹è¯•ä¸åŒé•¿åº¦çš„ç”Ÿæˆ
        test_configs = [
            {"max_new_tokens": 50, "name": "çŸ­æ–‡æœ¬ç”Ÿæˆ"},
            {"max_new_tokens": 100, "name": "ä¸­ç­‰æ–‡æœ¬ç”Ÿæˆ"},
            {"max_new_tokens": 200, "name": "é•¿æ–‡æœ¬ç”Ÿæˆ"}
        ]
        
        for config in test_configs:
            print(f"\n{config['name']} (max_new_tokens={config['max_new_tokens']}):")
            
            total_time = 0
            total_tokens = 0
            
            for i, prompt in enumerate(test_prompts):
                start_time = time.time()
                response = sgl.generate(
                    prompt, 
                    max_new_tokens=config['max_new_tokens'],
                    temperature=0.7
                )
                generation_time = time.time() - start_time
                
                total_time += generation_time
                total_tokens += len(response.text.split())
                
                print(f"  æµ‹è¯• {i+1}: {generation_time:.2f}s, {len(response.text.split())} tokens")
            
            avg_time = total_time / len(test_prompts)
            avg_tokens = total_tokens / len(test_prompts)
            tokens_per_second = avg_tokens / avg_time
            
            print(f"  å¹³å‡æ—¶é—´: {avg_time:.2f}s")
            print(f"  å¹³å‡tokenæ•°: {avg_tokens:.1f}")
            print(f"  ç”Ÿæˆé€Ÿåº¦: {tokens_per_second:.1f} tokens/s")
        
        return True
        
    except Exception as e:
        print(f"æ€§èƒ½æµ‹è¯•å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("SGLangæ··åˆç²¾åº¦åŠŸèƒ½æµ‹è¯•")
    print("=" * 60)
    
    # æœåŠ¡å™¨åœ°å€
    server_url = "http://127.0.0.1:8080"
    
    # æ£€æŸ¥æœåŠ¡å™¨æ˜¯å¦è¿è¡Œ
    print(f"æµ‹è¯•æœåŠ¡å™¨: {server_url}")
    
    # è¿è¡Œæµ‹è¯•
    tests = [
        ("å¥åº·æ£€æŸ¥", test_health_check, server_url),
        ("SGLang API", test_sglang_api, server_url),
        ("æ‰¹é‡ç”Ÿæˆ", test_batch_generation, server_url),
        ("æ··åˆç²¾åº¦ä¿¡æ¯", test_mixed_precision_info, server_url),
        ("æ€§èƒ½å¯¹æ¯”", test_performance_comparison, server_url)
    ]
    
    passed_tests = 0
    total_tests = len(tests)
    
    for test_name, test_func, *args in tests:
        try:
            if test_func(*args):
                print(f"âœ… {test_name} é€šè¿‡")
                passed_tests += 1
            else:
                print(f"âŒ {test_name} å¤±è´¥")
        except Exception as e:
            print(f"âŒ {test_name} å¼‚å¸¸: {e}")
    
    print("\n" + "=" * 60)
    print(f"æµ‹è¯•ç»“æœ: {passed_tests}/{total_tests} é€šè¿‡")
    
    if passed_tests == total_tests:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼æ··åˆç²¾åº¦åŠŸèƒ½æ­£å¸¸å·¥ä½œã€‚")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥ï¼Œè¯·æ£€æŸ¥æœåŠ¡å™¨çŠ¶æ€å’Œé…ç½®ã€‚")
    
    print("=" * 60)


if __name__ == "__main__":
    main()
