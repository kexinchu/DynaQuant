#!/usr/bin/env python3
"""
SGLangæ··åˆç²¾åº¦é›†æˆä½¿ç”¨ç¤ºä¾‹
å±•ç¤ºå¦‚ä½•çœŸæ­£ä½¿ç”¨SGLangçš„APIåŠ è½½æ··åˆç²¾åº¦æ¨¡å‹
"""

import os
import sys
import logging
import yaml
from pathlib import Path

# æ·»åŠ SGLangè·¯å¾„
sys.path.insert(0, str(Path(__file__).parent / "python"))

# è®¾ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


def create_mixed_precision_config():
    """åˆ›å»ºæ··åˆç²¾åº¦é…ç½®æ–‡ä»¶"""
    config = {
        "mixed_precision": {
            "fp16_path": "/path/to/fp16/weights",
            "fp8_path": "/path/to/fp8/weights", 
            "int4_path": "/path/to/int4/weights",
            "weight_mapping": {
                # æ³¨æ„åŠ›å±‚ä½¿ç”¨FP16
                "model.layers.0.self_attn.q_proj.weight": "fp16",
                "model.layers.0.self_attn.k_proj.weight": "fp16",
                "model.layers.0.self_attn.v_proj.weight": "fp16",
                "model.layers.0.self_attn.o_proj.weight": "fp16",
                
                # MLPå±‚ä½¿ç”¨FP8
                "model.layers.0.mlp.gate_proj.weight": "fp8",
                "model.layers.0.mlp.up_proj.weight": "fp8",
                "model.layers.0.mlp.down_proj.weight": "fp8",
                
                # ä¸“å®¶å±‚ä½¿ç”¨Int4
                "model.layers.0.mlp.experts.0.gate_proj.weight": "int4",
                "model.layers.0.mlp.experts.0.up_proj.weight": "int4",
                "model.layers.0.mlp.experts.0.down_proj.weight": "int4"
            }
        }
    }
    
    config_path = "example_mixed_precision_config.yaml"
    with open(config_path, 'w', encoding='utf-8') as f:
        yaml.dump(config, f, default_flow_style=False, allow_unicode=True)
    
    logger.info(f"åˆ›å»ºæ··åˆç²¾åº¦é…ç½®æ–‡ä»¶: {config_path}")
    return config_path


def example_sglang_mixed_precision_loading():
    """ç¤ºä¾‹ï¼šä½¿ç”¨SGLang APIåŠ è½½æ··åˆç²¾åº¦æ¨¡å‹"""
    print("=" * 60)
    print("SGLangæ··åˆç²¾åº¦åŠ è½½ç¤ºä¾‹")
    print("=" * 60)
    
    try:
        # å¯¼å…¥SGLangæ¨¡å—
        from sglang.srt.configs.model_config import ModelConfig
        from sglang.srt.configs.device_config import DeviceConfig
        from sglang.srt.configs.load_config import LoadConfig, LoadFormat
        from sglang.srt.model_loader.loader import DefaultModelLoader
        from sglang.srt.model_loader.sglang_mixed_precision_loader import (
            get_global_mixed_precision_loader
        )
        
        print("âœ“ SGLangæ¨¡å—å¯¼å…¥æˆåŠŸ")
        
        # åˆ›å»ºæ··åˆç²¾åº¦é…ç½®æ–‡ä»¶
        config_path = create_mixed_precision_config()
        
        # åˆ›å»ºSGLangé…ç½®
        model_config = ModelConfig(
            model_path="/path/to/your/model",  # æ›¿æ¢ä¸ºå®é™…æ¨¡å‹è·¯å¾„
            mixed_precision_config=config_path,
            dtype="auto",
            trust_remote_code=True
        )
        
        device_config = DeviceConfig(device="cuda")
        load_config = LoadConfig(load_format=LoadFormat.AUTO)
        
        print("âœ“ SGLangé…ç½®åˆ›å»ºæˆåŠŸ")
        print(f"  æ¨¡å‹è·¯å¾„: {model_config.model_path}")
        print(f"  æ··åˆç²¾åº¦é…ç½®: {model_config.mixed_precision_config}")
        print(f"  è®¾å¤‡: {device_config.device}")
        print(f"  æ•°æ®ç±»å‹: {model_config.dtype}")
        
        # åˆ›å»ºæ¨¡å‹åŠ è½½å™¨
        loader = DefaultModelLoader(load_config)
        print("âœ“ æ¨¡å‹åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        
        # æ³¨æ„ï¼šè¿™é‡Œä¸ä¼šå®é™…åŠ è½½æ¨¡å‹ï¼Œå› ä¸ºéœ€è¦çœŸå®çš„æ¨¡å‹æ–‡ä»¶
        # ä½†ä¼šæ¼”ç¤ºé…ç½®å’ŒåŠ è½½å™¨çš„åˆ›å»ºè¿‡ç¨‹
        print("\nğŸ“ ä½¿ç”¨è¯´æ˜:")
        print("1. å°†æ¨¡å‹è·¯å¾„æ›¿æ¢ä¸ºå®é™…çš„æ¨¡å‹è·¯å¾„")
        print("2. ç¡®ä¿æ··åˆç²¾åº¦æƒé‡æ–‡ä»¶å­˜åœ¨äºé…ç½®çš„è·¯å¾„ä¸­")
        print("3. è¿è¡Œä»¥ä¸‹ä»£ç åŠ è½½æ¨¡å‹:")
        print("   model = loader.load_model(model_config=model_config, device_config=device_config)")
        
        # æ¼”ç¤ºå¦‚ä½•è·å–æ··åˆç²¾åº¦åŠ è½½å™¨ä¿¡æ¯
        print("\nğŸ” æ··åˆç²¾åº¦åŠ è½½å™¨ä¿¡æ¯:")
        print("   - å½“æ¨¡å‹åŠ è½½æ—¶ï¼Œä¼šè‡ªåŠ¨åˆ›å»ºSGLangMixedPrecisionLoader")
        print("   - å¯ä»¥é€šè¿‡get_global_mixed_precision_loader()è·å–åŠ è½½å™¨å®ä¾‹")
        print("   - åŠ è½½å™¨ä¼šå¤„ç†ä¸åŒç²¾åº¦çš„æƒé‡åŠ è½½å’ŒGPTQåé‡åŒ–")
        
        return True
        
    except ImportError as e:
        print(f"âœ— SGLangæ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
        print("è¯·ç¡®ä¿SGLangå·²æ­£ç¡®å®‰è£…")
        return False
    except Exception as e:
        print(f"âœ— ç¤ºä¾‹æ‰§è¡Œå¤±è´¥: {e}")
        return False


def example_mixed_precision_loader_usage():
    """ç¤ºä¾‹ï¼šç›´æ¥ä½¿ç”¨æ··åˆç²¾åº¦åŠ è½½å™¨"""
    print("\n" + "=" * 60)
    print("æ··åˆç²¾åº¦åŠ è½½å™¨ç›´æ¥ä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    try:
        from sglang.srt.configs.model_config import ModelConfig
        from sglang.srt.model_loader.sglang_mixed_precision_loader import (
            SGLangMixedPrecisionLoader,
            MixedPrecisionConfig,
            create_mixed_precision_loader
        )
        
        # åˆ›å»ºæ··åˆç²¾åº¦é…ç½®
        mixed_precision_config = MixedPrecisionConfig(
            fp16_path="/path/to/fp16",
            fp8_path="/path/to/fp8",
            int4_path="/path/to/int4",
            weight_mapping={
                "model.layers.0.self_attn.q_proj.weight": "fp16",
                "model.layers.0.mlp.experts.0.up_proj.weight": "int4"
            }
        )
        
        # åˆ›å»ºæ¨¡å‹é…ç½®
        model_config = ModelConfig(
            model_path="/path/to/your/model",
            dtype="auto",
            trust_remote_code=True
        )
        
        # åˆ›å»ºæ··åˆç²¾åº¦åŠ è½½å™¨
        loader = SGLangMixedPrecisionLoader(model_config, mixed_precision_config)
        
        print("âœ“ æ··åˆç²¾åº¦åŠ è½½å™¨åˆ›å»ºæˆåŠŸ")
        print(f"  æƒé‡æ˜ å°„æ•°é‡: {len(mixed_precision_config.weight_mapping)}")
        print(f"  FP16è·¯å¾„: {mixed_precision_config.fp16_path}")
        print(f"  FP8è·¯å¾„: {mixed_precision_config.fp8_path}")
        print(f"  Int4è·¯å¾„: {mixed_precision_config.int4_path}")
        
        print("\nğŸ“ ä½¿ç”¨è¯´æ˜:")
        print("1. åˆ›å»ºMixedPrecisionConfigé…ç½®æ··åˆç²¾åº¦å‚æ•°")
        print("2. åˆ›å»ºSGLangMixedPrecisionLoaderå®ä¾‹")
        print("3. è°ƒç”¨load_model_weights()åŠ è½½æƒé‡åˆ°æ¨¡å‹")
        print("4. ä½¿ç”¨SGLangçš„æ¨ç†å¼•æ“è¿›è¡Œæ¨ç†")
        
        return True
        
    except Exception as e:
        print(f"âœ— æ··åˆç²¾åº¦åŠ è½½å™¨ç¤ºä¾‹å¤±è´¥: {e}")
        return False


def example_gptq_dequantization():
    """ç¤ºä¾‹ï¼šGPTQåé‡åŒ–"""
    print("\n" + "=" * 60)
    print("GPTQåé‡åŒ–ç¤ºä¾‹")
    print("=" * 60)
    
    try:
        import torch
        from sglang.srt.model_loader.sglang_mixed_precision_loader import SGLangGPTQDequantizer
        
        # åˆ›å»ºæ¨¡æ‹ŸGPTQæ•°æ®
        qweight = torch.randint(0, 16, (256, 768), dtype=torch.int32)
        qzeros = torch.randint(0, 16, (16, 96), dtype=torch.int32)
        scales = torch.randn(16, 768, dtype=torch.float16)
        
        # æ‰§è¡Œåé‡åŒ–
        weight = SGLangGPTQDequantizer.dequantize_gptq_weight(qweight, qzeros, scales)
        
        print("âœ“ GPTQåé‡åŒ–æˆåŠŸ")
        print(f"  è¾“å…¥å½¢çŠ¶: qweight{qweight.shape}, qzeros{qzeros.shape}, scales{scales.shape}")
        print(f"  è¾“å‡ºå½¢çŠ¶: {weight.shape}")
        print(f"  è¾“å‡ºç±»å‹: {weight.dtype}")
        
        print("\nğŸ“ ä½¿ç”¨è¯´æ˜:")
        print("1. GPTQåé‡åŒ–ä¼šè‡ªåŠ¨åœ¨åŠ è½½Int4æƒé‡æ—¶æ‰§è¡Œ")
        print("2. æ”¯æŒæ ‡å‡†çš„GPTQæ ¼å¼ï¼šqweight, qzeros, scales, g_idx")
        print("3. è‡ªåŠ¨å¤„ç†ç»´åº¦åŒ¹é…å’Œè®¾å¤‡è½¬æ¢")
        
        return True
        
    except Exception as e:
        print(f"âœ— GPTQåé‡åŒ–ç¤ºä¾‹å¤±è´¥: {e}")
        return False


def main():
    """ä¸»å‡½æ•°"""
    print("SGLangæ··åˆç²¾åº¦é›†æˆä½¿ç”¨ç¤ºä¾‹")
    print("=" * 60)
    
    # è¿è¡Œç¤ºä¾‹
    examples = [
        ("SGLangæ··åˆç²¾åº¦åŠ è½½", example_sglang_mixed_precision_loading),
        ("æ··åˆç²¾åº¦åŠ è½½å™¨ä½¿ç”¨", example_mixed_precision_loader_usage),
        ("GPTQåé‡åŒ–", example_gptq_dequantization),
    ]
    
    results = []
    for example_name, example_func in examples:
        print(f"\nè¿è¡Œç¤ºä¾‹: {example_name}")
        try:
            result = example_func()
            results.append((example_name, result))
        except Exception as e:
            print(f"âœ— ç¤ºä¾‹å¼‚å¸¸: {e}")
            results.append((example_name, False))
    
    # æ˜¾ç¤ºç»“æœ
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹æ‰§è¡Œç»“æœ")
    print("=" * 60)
    
    for example_name, result in results:
        status = "âœ“ æˆåŠŸ" if result else "âœ— å¤±è´¥"
        print(f"{example_name}: {status}")
    
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    print(f"\næ€»è®¡: {passed}/{total} ä¸ªç¤ºä¾‹æˆåŠŸ")
    
    if passed == total:
        print("ğŸ‰ æ‰€æœ‰ç¤ºä¾‹æ‰§è¡ŒæˆåŠŸï¼")
        print("\nä¸‹ä¸€æ­¥:")
        print("1. å‡†å¤‡çœŸå®çš„æ¨¡å‹æ–‡ä»¶å’Œæ··åˆç²¾åº¦æƒé‡")
        print("2. ä¿®æ”¹é…ç½®æ–‡ä»¶ä¸­çš„è·¯å¾„")
        print("3. ä½¿ç”¨SGLang APIåŠ è½½å’Œæ¨ç†æ¨¡å‹")
        print("4. äº«å—SGLangçš„é«˜æ€§èƒ½æ··åˆç²¾åº¦æ¨ç†ï¼")
    else:
        print("âš  éƒ¨åˆ†ç¤ºä¾‹å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç¯å¢ƒé…ç½®ã€‚")
    
    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
    config_path = "example_mixed_precision_config.yaml"
    if os.path.exists(config_path):
        try:
            os.remove(config_path)
            print(f"\næ¸…ç†ä¸´æ—¶æ–‡ä»¶: {config_path}")
        except:
            pass


if __name__ == "__main__":
    main()
